{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating incorrect answers for questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = 'embeddings\\glove.6B.300d.txt'\n",
    "tmp_file = 'embeddings\\word2vec-glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove2word2vec(glove_file, tmp_file)\n",
    "model = KeyedVectors.load_word2vec_format(tmp_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic cosime similarity on a single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('william', 0.5641534328460693),\n",
       " ('james', 0.5441264510154724),\n",
       " ('j.', 0.5343754887580872),\n",
       " ('h.', 0.5330929756164551),\n",
       " ('d.', 0.5264898538589478),\n",
       " ('richard', 0.5263983011245728),\n",
       " ('john', 0.5211343765258789),\n",
       " ('henry', 0.5162783861160278),\n",
       " ('b.', 0.5118230581283569),\n",
       " ('l.', 0.508935809135437)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['robert'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distractors(answer, count):\n",
    "    answer = str.lower(answer)\n",
    "    \n",
    "    ##Extracting closest words for the answer. \n",
    "    try:\n",
    "        closestWords = model.most_similar(positive=[answer], topn=count)\n",
    "    except:\n",
    "        #In case the word is not in the vocabulary, or other problem not loading embeddings\n",
    "        return []\n",
    "\n",
    "    #Return count many distractors\n",
    "    # retrieving only the text and taking count amount of samples \n",
    "    distractors = list(map(lambda x: x[0], closestWords))[0:count]\n",
    "  \n",
    "    return distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('writing', 0.6969849467277527),\n",
       " ('read', 0.6291235089302063),\n",
       " ('wrote', 0.6251993179321289),\n",
       " ('written', 0.6065735816955566),\n",
       " ('publish', 0.5670630931854248),\n",
       " (\"'d\", 0.5343195796012878),\n",
       " ('writes', 0.5341792702674866),\n",
       " ('tell', 0.5337096452713013),\n",
       " ('you', 0.5316603779792786),\n",
       " ('books', 0.5285096168518066)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['write'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1914', 0.6271713972091675),\n",
       " ('1918', 0.6049230098724365),\n",
       " ('wars', 0.5950419306755066),\n",
       " ('1919', 0.5936863422393799),\n",
       " ('1915', 0.592497706413269),\n",
       " ('1913', 0.5884469747543335),\n",
       " ('1920', 0.5811989307403564),\n",
       " ('balkans', 0.580984354019165),\n",
       " ('1916', 0.5671558380126953),\n",
       " ('1921', 0.5582135319709778)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['1912', 'balkan', 'war'], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using most common words and different approach for numerical and non-numerical words\n",
    "- used most-common words to tag importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_distractors_phrase(phrase, count = 4):\n",
    "    pass\n",
    "    doc = nlp(phrase)\n",
    "    # label to-drop 'at around 180 years' - [1, 1, 0, 1]\n",
    "\n",
    "    wordImportance = [1] * len(doc)\n",
    "        \n",
    "    # common words\n",
    "    for i in range(len(doc)):\n",
    "        word = doc[i].lemma_.lower()  \n",
    "        if word in StopWords.SkipWords:\n",
    "            wordImportance[i] = 0\n",
    "    \n",
    "    # if multiple words left - keep the best tf/idf scores. just occurence would suffice for now\n",
    "    wordOccurences = load_pickle('../../data/squad-v1/idf/word-occurances-paragraph.pkl')\n",
    "    for token in doc:\n",
    "        print(wordOccurences[token.text] if token.text in wordOccurences else 0)\n",
    "    \n",
    "    #for meaningful words, generate similar\n",
    "    # keep formating - case sensitivity \n",
    "    # mix and match\n",
    "    # relationship between mixed similar words?\n",
    "    \n",
    "    return wordImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate_distractors_phrase('at around 180 years six to seven months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "# TODO: rename method names with '_'\n",
    "def dump_pickle(content, fileName: str):\n",
    "    \"\"\"Save a python object as a pickle.\n",
    "    \n",
    "    Args:\n",
    "        content: Python object.\n",
    "        fileName (str): File name and path, relative to the current executed file.\n",
    "    \"\"\"\n",
    "    pickleFile = open(fileName, 'wb')\n",
    "    cPickle.dump(content, pickleFile, -1)\n",
    "    pickleFile.close()\n",
    "\n",
    "\n",
    "def load_pickle(fileName: str):\n",
    "    \"\"\"Load a python object saved as a pickle.\n",
    "    \n",
    "    Args:\n",
    "        fileName (str): File name and path to the pickle object\n",
    "    \n",
    "    Returns:\n",
    "        The python object saved in the pickle.\n",
    "    \"\"\"\n",
    "    file = open(fileName, 'rb')\n",
    "    content = cPickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def pickle_exists(fileName:str) -> bool:\n",
    "    \"\"\"Check whether a pickle exists.\n",
    "    \n",
    "    Args:\n",
    "        fileName (str): File name and path to look for.\n",
    "    \n",
    "    Returns:\n",
    "        bool: Whether it exists.\n",
    "    \"\"\"\n",
    "    \n",
    "    file = Path(fileName)\n",
    "\n",
    "    if file.is_file():\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def save_pickle_dated(content, path: str,  revision: str, contentName: str):\n",
    "    \"\"\" Save a pickle file with date information in the name.\n",
    "    \n",
    "    Args:\n",
    "        content: Python object to be pickled.\n",
    "        path (str): Path to the save directory. \n",
    "        revision (str): Notable change from the previous version.\n",
    "        contentName (str): Object type that's being saved. (e.g. test, dev, model)\n",
    "    \"\"\"\n",
    "    now = datetime.datetime.now()\n",
    "    pickleName = \"{0}{1:02d}{2:02d}-{3}{4}-{5}-{6}.pkl\".format(now.year, now.month, now.day, now.hour, now.minute, revision, contentName)\n",
    "\n",
    "    dump_pickle(content, path + pickleName)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- separate importance tagging for numerals and non-numerals\n",
    "\n",
    "### Numerals and Non-numerals importance tagging\n",
    "Decided upon having two separate paths for tagging important words. One for numerals and one for non-numerals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_words(phrase, count = 2):\n",
    "    doc = nlp(phrase)\n",
    "    # label to-drop 'at around 180 years' - [1, 1, 0, 1]\n",
    "    wordImportance = [1] * len(doc)\n",
    "    wordOccurences= load_pickle('idf/word-occurances-paragraph.pkl')\n",
    "    \n",
    "    phraseOcc = [0] * len(doc)\n",
    "    \n",
    "    for i in range(len(doc)):\n",
    "        occurences = wordOccurences[doc[i].text] if doc[i].text in wordOccurences else 0\n",
    "        phraseOcc[i] = occurences \n",
    "        \n",
    "    treshold = sorted(phraseOcc)[count - 1]\n",
    "    #Beware. May yield more than count amount if the treshold is 0 and more than one have 0 occurences.\n",
    "    \n",
    "    for i in range(len(doc)):\n",
    "        if phraseOcc[i] > treshold:\n",
    "            wordImportance[i] = 0\n",
    "    \n",
    "    return wordImportance\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_important_words('at around 180 years', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_words(phrase):\n",
    "    doc = nlp(phrase)\n",
    "    \n",
    "    wordImportance = [0] * len(doc)\n",
    "    \n",
    "    for i in range(len(doc)):\n",
    "        if doc[i].like_num:\n",
    "            wordImportance[i] = 1\n",
    "            \n",
    "    return wordImportance    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numerical_words('at around 180 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_numerical_words('from six to seven months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distractors_phrase(phrase, count = 4):\n",
    "    pass\n",
    "    doc = nlp(phrase)\n",
    "    wordsCount = len(doc)\n",
    "    \n",
    "    #Check type of phrase\n",
    "    isNumerical = any(token.like_num for token in doc)\n",
    "    \n",
    "    if isNumerical:\n",
    "        wordImportance = get_numerical_words(phrase)\n",
    "    else:\n",
    "        wordImportance = get_most_important_words(phrase, 4)\n",
    "        \n",
    "    # Generate similar\n",
    "    similarForWords = []\n",
    "    \n",
    "    for i in range(wordsCount):\n",
    "        currSimilar = []\n",
    "        \n",
    "        if wordImportance[i] == 1:\n",
    "            #TODO: Decide upon amount of similars per word\n",
    "            currSimilar = generate_distractors(doc[i].text, 3)\n",
    "        \n",
    "        similarForWords.append(currSimilar)\n",
    "        \n",
    "    # Mix\n",
    "    #TODO: Generate all possible combinatons. Order them. Take co\n",
    "    \n",
    "    #Two words only\n",
    "    for i in range(wordsCount):\n",
    "        for j in range(wordsCount):\n",
    "            pass\n",
    "    \n",
    "    return similarForWords\n",
    "    # keep formating - case sensitivity \n",
    "    # mix and match\n",
    "    # relationship between mixed similar words?\n",
    "    \n",
    "    return wordImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarForWords = generate_distractors_phrase('the koala inhabits north and south whales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['probo', 'koalas', 'orangutan'],\n",
       " ['inhabit', 'inhabiting', 'habitats'],\n",
       " [],\n",
       " [],\n",
       " ['north', 'africa', 'korea'],\n",
       " ['whale', 'humpback', 'minke']]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarForWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating all mixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All combinations of mixes\n",
    "- Recursively generating all possible mixes of distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractor_combinations(currPhrase, similarForWords, i):\n",
    "    \n",
    "    currCombinations = []\n",
    "    \n",
    "    for j in range(i, len(similarForWords)):\n",
    "        if similarForWords[j] != []:\n",
    "            for distractor in similarForWords[j]:\n",
    "                newPhrase = currPhrase + ' ' + distractor\n",
    "                \n",
    "                newCombinations = get_distractor_combinations(newPhrase, similarForWords, j + 1)\n",
    "                \n",
    "                currCombinations.append(newCombinations)   \n",
    "#                 currCombinations.extend(newCombinations)   \n",
    "                \n",
    "#                 currCombinations = [*currCombinations,*get_distractor_combinations(newPhrase, similarForWords, j + 1)]\n",
    "            break\n",
    "    \n",
    "    if currCombinations == []:\n",
    "        return currPhrase\n",
    "    else:\n",
    "        return currCombinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarForWords = [\n",
    "    ['the'],\n",
    "    ['koala', 'kangaroo'],\n",
    "    ['inhabits'],\n",
    "    ['north'],\n",
    "    ['and'],\n",
    "    ['south', 'west', 'east'],\n",
    "    ['whales', 'sydney']]\n",
    "\n",
    "currPhrase = 'the koala inhabits north and south whales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[[[['_ the koala inhabits north and south whales',\n",
       "       '_ the koala inhabits north and south sydney'],\n",
       "      ['_ the koala inhabits north and west whales',\n",
       "       '_ the koala inhabits north and west sydney'],\n",
       "      ['_ the koala inhabits north and east whales',\n",
       "       '_ the koala inhabits north and east sydney']]]]],\n",
       "  [[[[['_ the kangaroo inhabits north and south whales',\n",
       "       '_ the kangaroo inhabits north and south sydney'],\n",
       "      ['_ the kangaroo inhabits north and west whales',\n",
       "       '_ the kangaroo inhabits north and west sydney'],\n",
       "      ['_ the kangaroo inhabits north and east whales',\n",
       "       '_ the kangaroo inhabits north and east sydney']]]]]]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_distractor_combinations('_', similarForWords, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flattening nested arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/5286541/how-can-i-flatten-lists-without-splitting-strings\n",
    "\n",
    "def flatten(phrases):\n",
    "    for x in phrases:\n",
    "        if hasattr(x, '__iter__') and not isinstance(x, str):\n",
    "            for y in flatten(x):\n",
    "                yield y\n",
    "        else:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[[[['_ the koala inhabits north and south whales',\n",
       "       '_ the koala inhabits north and south sydney'],\n",
       "      ['_ the koala inhabits north and west whales',\n",
       "       '_ the koala inhabits north and west sydney'],\n",
       "      ['_ the koala inhabits north and east whales',\n",
       "       '_ the koala inhabits north and east sydney']]]]],\n",
       "  [[[[['_ the kangaroo inhabits north and south whales',\n",
       "       '_ the kangaroo inhabits north and south sydney'],\n",
       "      ['_ the kangaroo inhabits north and west whales',\n",
       "       '_ the kangaroo inhabits north and west sydney'],\n",
       "      ['_ the kangaroo inhabits north and east whales',\n",
       "       '_ the kangaroo inhabits north and east sydney']]]]]]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = get_distractor_combinations('_', similarForWords, 0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_ the koala inhabits north and south whales',\n",
       " '_ the koala inhabits north and south sydney',\n",
       " '_ the koala inhabits north and west whales',\n",
       " '_ the koala inhabits north and west sydney',\n",
       " '_ the koala inhabits north and east whales',\n",
       " '_ the koala inhabits north and east sydney',\n",
       " '_ the kangaroo inhabits north and south whales',\n",
       " '_ the kangaroo inhabits north and south sydney',\n",
       " '_ the kangaroo inhabits north and west whales',\n",
       " '_ the kangaroo inhabits north and west sydney',\n",
       " '_ the kangaroo inhabits north and east whales',\n",
       " '_ the kangaroo inhabits north and east sydney']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(flatten(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating new phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace word\n",
    "#TODO add index or start/end of word\n",
    "## v1\n",
    "def create_phrase(phrase, replace, replaceWith):\n",
    "    return phrase.replace(replace, replaceWith)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'koala is a great animal'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_phrase('koala is a good animal', 'good', 'great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create phrase v2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace word\n",
    "#TODO add index or start/end of word\n",
    "## v2\n",
    "def create_phrase(phraseList, replaceIndex, replaceWith):\n",
    "    newList = phraseList.copy()\n",
    "    newList[replaceIndex] = replaceWith\n",
    "    return newList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['koala', 'is', 'a', 'great', 'animal']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_phrase(['koala', 'is', 'a', 'good', 'animal'], 3, 'great')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom flatting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_distractor_lists(combinations, newCombinations):    \n",
    "    if any(newCombinations):\n",
    "        # if single list of string is returned, bottom of recursion\n",
    "        if isinstance(newCombinations[0], str):\n",
    "            combinations.append(newCombinations)\n",
    "        # list of lists returned\n",
    "        else:\n",
    "             for newCombination in newCombinations:\n",
    "                combinations.append(newCombination)\n",
    "\n",
    "    return combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractor_combinations(currPhrase, wordChoices, i = 0):\n",
    "    \n",
    "    currCombinations = []\n",
    "    \n",
    "    for j in range(i, len(wordChoices)):\n",
    "        if wordChoices[j] != []:\n",
    "            #TODO add correct answer in the mix as well\n",
    "            for distractor in wordChoices[j]:\n",
    "                newPhrase = create_phrase(currPhrase, j, distractor)\n",
    "                \n",
    "                # Mix correct answers as well\n",
    "                newCombinations = get_distractor_combinations(newPhrase, wordChoices, j + 1)\n",
    "                \n",
    "                currCombinations = join_distractor_lists(currCombinations, newCombinations)\n",
    "   \n",
    "            break\n",
    "    \n",
    "    if currCombinations == []:\n",
    "        return currPhrase\n",
    "    else:\n",
    "        return currCombinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarForWords = [[],\n",
    " ['kangaroo', 'whombat'],\n",
    " [],\n",
    " [],\n",
    " [],\n",
    " ['west', 'north'],\n",
    " ['whales', 'europe']]\n",
    "currPhrase = ['the', 'koala', 'inhabits', 'north', 'and', 'south', 'australia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'kangaroo', 'inhabits', 'north', 'and', 'west', 'whales'],\n",
       " ['the', 'kangaroo', 'inhabits', 'north', 'and', 'west', 'europe'],\n",
       " ['the', 'kangaroo', 'inhabits', 'north', 'and', 'north', 'whales'],\n",
       " ['the', 'kangaroo', 'inhabits', 'north', 'and', 'north', 'europe'],\n",
       " ['the', 'whombat', 'inhabits', 'north', 'and', 'west', 'whales'],\n",
       " ['the', 'whombat', 'inhabits', 'north', 'and', 'west', 'europe'],\n",
       " ['the', 'whombat', 'inhabits', 'north', 'and', 'north', 'whales'],\n",
       " ['the', 'whombat', 'inhabits', 'north', 'and', 'north', 'europe']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = get_distractor_combinations(currPhrase, similarForWords)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BUG - No choices, returns [correct], rather than [[correct]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarForWords = [[],\n",
    " [],\n",
    " [],\n",
    " [],\n",
    " [],\n",
    " []]\n",
    "currPhrase = ['Phascolarctidae', 'and', 'its', 'closest', 'living', 'relatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Phascolarctidae', 'and', 'its', 'closest', 'living', 'relatives']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = get_distractor_combinations(currPhrase, similarForWords)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractor_combinations(currPhrase, wordChoices, i = 0):\n",
    "    \n",
    "    currCombinations = []\n",
    "    \n",
    "    #If not choices bug\n",
    "    if not any(wordChoices):\n",
    "        currCombinations.append(currPhrase)\n",
    "        return currCombinations\n",
    "    \n",
    "    for j in range(i, len(wordChoices)):\n",
    "        if wordChoices[j] != []:\n",
    "            #TODO add correct answer in the mix as well\n",
    "            for distractor in wordChoices[j]:\n",
    "                newPhrase = create_phrase(currPhrase, j, distractor)\n",
    "                \n",
    "                # Mix correct answers as well\n",
    "                newCombinations = get_distractor_combinations(newPhrase, wordChoices, j + 1)\n",
    "                \n",
    "                currCombinations = join_distractor_lists(currCombinations, newCombinations)\n",
    "   \n",
    "            break\n",
    "    \n",
    "    if currCombinations == []:\n",
    "        return currPhrase\n",
    "    else:\n",
    "        return currCombinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarForWords = [[],\n",
    " [],\n",
    " [],\n",
    " [],\n",
    " [],\n",
    " []]\n",
    "\n",
    "any(similarForWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Phascolarctidae', 'and', 'its', 'closest', 'living', 'relatives']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[currPhrase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distractors_phrase(phrase, count = 4):\n",
    "    pass\n",
    "    doc = nlp(phrase)\n",
    "    wordsCount = len(doc)\n",
    "    \n",
    "    #Check type of phrase\n",
    "    isNumerical = any(token.like_num for token in doc)\n",
    "    \n",
    "    if isNumerical:\n",
    "        wordImportance = get_numerical_words(phrase)\n",
    "    else:\n",
    "        wordImportance = get_most_important_words(phrase, 2)\n",
    "        \n",
    "    # Generate similar\n",
    "    similarWords = []\n",
    "    \n",
    "    for i in range(wordsCount):\n",
    "        currSimilar = []\n",
    "        \n",
    "        if wordImportance[i] == 1:\n",
    "            #TODO: Decide upon amount of similars per word\n",
    "            currSimilar = generate_distractors(doc[i].text, 3)\n",
    "        \n",
    "        similarWords.append(currSimilar)\n",
    "        \n",
    "    #Add correct words to the mix\n",
    "    for i in range(wordsCount):\n",
    "        if any(similarWords[i]):\n",
    "            similarWords[i].append(doc[i].text)\n",
    "        \n",
    "    # Mix\n",
    "    phraseList = [token.text for token in doc]\n",
    "    distractors = get_distractor_combinations(phraseList, similarWords)\n",
    "    \n",
    "    #TODO pick best distractors - remove worst(duplicates or some..)\n",
    "    \n",
    "    import random\n",
    "    bestDistractors = random.sample(distractors, 4)\n",
    "\n",
    "    #TODO format distractors according to case\n",
    "    \n",
    "    \n",
    "    # relationship between mixed similar words?\n",
    "    \n",
    "    return wordImportance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = generate_distractors_phrase('from six to seven months')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def filter_distractors(distractors, doc, count):\n",
    "    \n",
    "    #TODO remove bad stuff and correct answer\n",
    "    \n",
    "    bestDistractors = random.sample(distractors, 4)\n",
    "\n",
    "    return bestDistractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_distractor(wordsList, doc):\n",
    "    result = wordsList[0].title() if doc[0].text.istitle() else wordsList[0]\n",
    "    \n",
    "    for i in range(1, len(doc)):\n",
    "        if not doc[i].is_punct and not doc[i - 1].is_punct:\n",
    "            result += ' '\n",
    "        result += wordsList[i].title() if doc[i].text.istitle() else wordsList[i]\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsList = ['from', 'five', '-', 'eight', 'months']\n",
    "doc = nlp('From four-Seven months')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From five-Eight months'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_distractor(wordsList, doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distractors_phrase(phrase, count = 4):\n",
    "    doc = nlp(phrase)\n",
    "    wordsCount = len(doc)\n",
    "    \n",
    "    #Check type of phrase\n",
    "    isNumerical = any(token.like_num for token in doc)\n",
    "    \n",
    "    if isNumerical:\n",
    "        wordImportance = get_numerical_words(phrase)\n",
    "    else:\n",
    "        wordImportance = get_most_important_words(phrase, 1)\n",
    "        \n",
    "    # Generate similar\n",
    "    similarWords = []\n",
    "    \n",
    "    for i in range(wordsCount):\n",
    "        currSimilar = []\n",
    "        \n",
    "        if wordImportance[i] == 1:\n",
    "            #TODO: Decide upon amount of similars per word\n",
    "            currSimilar = generate_distractors(doc[i].text, 3)\n",
    "        \n",
    "        similarWords.append(currSimilar)\n",
    "        \n",
    "    #Add correct words to the mix\n",
    "    for i in range(wordsCount):\n",
    "        if any(similarWords[i]):\n",
    "            similarWords[i].append(doc[i].text)\n",
    "        \n",
    "    # Mix\n",
    "    phraseList = [token.text for token in doc]\n",
    "    distractors = get_distractor_combinations(phraseList, similarWords)\n",
    "    \n",
    "    #TODO pick best distractors - remove worst(duplicates or some..)\n",
    "    bestDisctractors = filter_distractors(distractors, doc, count)\n",
    "\n",
    "    #format distractors according to case\n",
    "    result = list(map(lambda distractor: format_distractor(distractor, doc), bestDisctractors)) \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In the first five-seven months.',\n",
       " 'In the first eight-five months.',\n",
       " 'In the first eight-eight months.',\n",
       " 'In the first six-eight months.']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_distractors_phrase('In the first six-seven months.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zoologist James Green.',\n",
       " 'Botanist James Green.',\n",
       " 'Ornithologist J. Purple.',\n",
       " 'Botanist Robert Purple.']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_distractors_phrase('Botanist Robert Green.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
